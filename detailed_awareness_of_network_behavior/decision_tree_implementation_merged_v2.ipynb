{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets by attack category:\n",
    "\n",
    "#### scanning and normal:\n",
    "* Network_dataset_1.csv (Around half are normal, half are scanning)\n",
    "* Network_dataset_2.csv (Mostly scanning attacks)\n",
    "* Network_dataset_3.csv (Mostly scanning attacks)\n",
    "* Network_dataset_4.csv (Mostly scanning attacks)\n",
    "* Network_dataset_5.csv (Mostly scanning attacks)\n",
    "* Network_dataset_6.csv (Mostly scanning attacks)\n",
    "* Network_dataset_7.csv (Mostly scanning attacks)\n",
    "\n",
    "#### scanning, dos, and normal:\n",
    "* Network_dataset_8.csv (Mostly scanning and dos attacks)\n",
    "\n",
    "#### dos and normal:\n",
    "* Network_dataset_9.csv     (Mostly dos attacks)\n",
    "* Network_dataset_10.csv    (Mostly dos attacks)\n",
    "\n",
    "#### dos, injection, and normal:\n",
    "* Network_dataset_11.csv    (Mostly dos and injection attacks)\n",
    "\n",
    "#### injection, ddos, and normal:\n",
    "* Network_dataset_12.csv    (Mostly ddos and injection attacks)\n",
    "\n",
    "#### ddos and normal:\n",
    "* Network_dataset_13.csv    (Mostly ddos attacks)\n",
    "* Network_dataset_14.csv    (Mostly ddos attacks)\n",
    "* Network_dataset_15.csv    (Mostly ddos attacks)\n",
    "* Network_dataset_16.csv    (Mostly ddos attacks)\n",
    "* Network_dataset_17.csv    (Mostly ddos attacks)\n",
    "\n",
    "#### password, ddos, and normal:\n",
    "* Network_dataset_18.csv    (Mostly ddos and password attacks)\n",
    "\n",
    "#### password and normal:\n",
    "* Network_dataset_19.csv    (Mostly password attacks)\n",
    "\n",
    "#### xss, password, and normal:\n",
    "* Network_dataset_20.csv    (Mostly xss and password attacks)\n",
    "\n",
    "#### xss and normal:\n",
    "* Network_dataset_21.csv    (Mostly xss attacks)\n",
    "\n",
    "#### xss, normal, ransomware, and backdoor:\n",
    "* Network_dataset_22.csv    (Mostly xss, normal, and backdoor)\n",
    "\n",
    "#### backdoor, normal, and mitm:\n",
    "* Network_dataset_23.csv    (Mostly backdoor attacks)\n",
    "\n",
    "#### A bit of every type of attack:\n",
    "* train_test_network.csv\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jaero\\AppData\\Local\\Temp\\ipykernel_30872\\1765030144.py:4: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  newdata = pd.read_csv('Network_dataset_1.csv')\n",
      "C:\\Users\\jaero\\AppData\\Local\\Temp\\ipykernel_30872\\1765030144.py:12: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  newdata9 = pd.read_csv('Network_dataset_22.csv')\n",
      "C:\\Users\\jaero\\AppData\\Local\\Temp\\ipykernel_30872\\1765030144.py:13: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  newdata10 = pd.read_csv('Network_dataset_23.csv')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Get all datasets\n",
    "newdata = pd.read_csv('Network_dataset_1.csv')\n",
    "newdata2 = pd.read_csv('Network_dataset_8.csv')\n",
    "newdata3 = pd.read_csv('Network_dataset_10.csv')\n",
    "newdata4 = pd.read_csv('Network_dataset_11.csv')\n",
    "newdata5 = pd.read_csv('Network_dataset_12.csv')\n",
    "newdata6 = pd.read_csv('Network_dataset_14.csv')\n",
    "newdata7 = pd.read_csv('Network_dataset_19.csv')\n",
    "newdata8 = pd.read_csv('Network_dataset_21.csv')\n",
    "newdata9 = pd.read_csv('Network_dataset_22.csv')\n",
    "newdata10 = pd.read_csv('Network_dataset_23.csv')\n",
    "\n",
    "# Merge the datasets\n",
    "premergedData = [newdata, newdata2, newdata3, newdata4, newdata5, \n",
    "                 newdata6, newdata7, newdata8, newdata9, newdata10]\n",
    "                 \n",
    "mergedData = pd.concat(premergedData) #NOTE: This generates HUGE dataset\n",
    "\n",
    "df = mergedData # Temporary variable\n",
    "\n",
    "# Get train-test dataset\n",
    "##newdata11 = pd.read_csv('train_test_network.csv')\n",
    "\n",
    "### Create giant dataset\n",
    "##predf = [mergedData2, newdata6]\n",
    "##df = pd.concat(premergedData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts</th>\n",
       "      <th>src_ip</th>\n",
       "      <th>src_port</th>\n",
       "      <th>dst_ip</th>\n",
       "      <th>dst_port</th>\n",
       "      <th>proto</th>\n",
       "      <th>service</th>\n",
       "      <th>duration</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>...</th>\n",
       "      <th>http_response_body_len</th>\n",
       "      <th>http_status_code</th>\n",
       "      <th>http_user_agent</th>\n",
       "      <th>http_orig_mime_types</th>\n",
       "      <th>http_resp_mime_types</th>\n",
       "      <th>weird_name</th>\n",
       "      <th>weird_addl</th>\n",
       "      <th>weird_notice</th>\n",
       "      <th>label</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1554198358</td>\n",
       "      <td>3.122.49.24</td>\n",
       "      <td>1883</td>\n",
       "      <td>192.168.1.152</td>\n",
       "      <td>52976</td>\n",
       "      <td>tcp</td>\n",
       "      <td>-</td>\n",
       "      <td>80549.530260</td>\n",
       "      <td>1762852</td>\n",
       "      <td>41933215</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>bad_TCP_checksum</td>\n",
       "      <td>-</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1554198358</td>\n",
       "      <td>192.168.1.79</td>\n",
       "      <td>47260</td>\n",
       "      <td>192.168.1.255</td>\n",
       "      <td>15600</td>\n",
       "      <td>udp</td>\n",
       "      <td>-</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1554198359</td>\n",
       "      <td>192.168.1.152</td>\n",
       "      <td>1880</td>\n",
       "      <td>192.168.1.152</td>\n",
       "      <td>51782</td>\n",
       "      <td>tcp</td>\n",
       "      <td>-</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>bad_TCP_checksum</td>\n",
       "      <td>-</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1554198359</td>\n",
       "      <td>192.168.1.152</td>\n",
       "      <td>34296</td>\n",
       "      <td>192.168.1.152</td>\n",
       "      <td>10502</td>\n",
       "      <td>tcp</td>\n",
       "      <td>-</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1554198362</td>\n",
       "      <td>192.168.1.152</td>\n",
       "      <td>46608</td>\n",
       "      <td>192.168.1.190</td>\n",
       "      <td>53</td>\n",
       "      <td>udp</td>\n",
       "      <td>dns</td>\n",
       "      <td>0.000549</td>\n",
       "      <td>0</td>\n",
       "      <td>298</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>bad_UDP_checksum</td>\n",
       "      <td>-</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339016</th>\n",
       "      <td>1556549156</td>\n",
       "      <td>192.168.1.195</td>\n",
       "      <td>50003</td>\n",
       "      <td>192.168.1.1</td>\n",
       "      <td>41952</td>\n",
       "      <td>tcp</td>\n",
       "      <td>-</td>\n",
       "      <td>0.021031</td>\n",
       "      <td>383</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339017</th>\n",
       "      <td>1556549156</td>\n",
       "      <td>192.168.1.195</td>\n",
       "      <td>50004</td>\n",
       "      <td>192.168.1.1</td>\n",
       "      <td>41952</td>\n",
       "      <td>tcp</td>\n",
       "      <td>-</td>\n",
       "      <td>0.021857</td>\n",
       "      <td>226</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339018</th>\n",
       "      <td>1556549156</td>\n",
       "      <td>192.168.1.195</td>\n",
       "      <td>50003</td>\n",
       "      <td>192.168.1.1</td>\n",
       "      <td>41952</td>\n",
       "      <td>tcp</td>\n",
       "      <td>-</td>\n",
       "      <td>0.018836</td>\n",
       "      <td>383</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339019</th>\n",
       "      <td>1556549156</td>\n",
       "      <td>192.168.1.195</td>\n",
       "      <td>50003</td>\n",
       "      <td>192.168.1.1</td>\n",
       "      <td>41952</td>\n",
       "      <td>tcp</td>\n",
       "      <td>-</td>\n",
       "      <td>0.018866</td>\n",
       "      <td>383</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339020</th>\n",
       "      <td>1556549156</td>\n",
       "      <td>192.168.1.195</td>\n",
       "      <td>50005</td>\n",
       "      <td>192.168.1.1</td>\n",
       "      <td>41952</td>\n",
       "      <td>tcp</td>\n",
       "      <td>-</td>\n",
       "      <td>0.034534</td>\n",
       "      <td>383</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9339021 rows Ã— 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                ts         src_ip  src_port         dst_ip  dst_port proto   \n",
       "0       1554198358    3.122.49.24      1883  192.168.1.152     52976   tcp  \\\n",
       "1       1554198358   192.168.1.79     47260  192.168.1.255     15600   udp   \n",
       "2       1554198359  192.168.1.152      1880  192.168.1.152     51782   tcp   \n",
       "3       1554198359  192.168.1.152     34296  192.168.1.152     10502   tcp   \n",
       "4       1554198362  192.168.1.152     46608  192.168.1.190        53   udp   \n",
       "...            ...            ...       ...            ...       ...   ...   \n",
       "339016  1556549156  192.168.1.195     50003    192.168.1.1     41952   tcp   \n",
       "339017  1556549156  192.168.1.195     50004    192.168.1.1     41952   tcp   \n",
       "339018  1556549156  192.168.1.195     50003    192.168.1.1     41952   tcp   \n",
       "339019  1556549156  192.168.1.195     50003    192.168.1.1     41952   tcp   \n",
       "339020  1556549156  192.168.1.195     50005    192.168.1.1     41952   tcp   \n",
       "\n",
       "       service      duration src_bytes  dst_bytes  ... http_response_body_len   \n",
       "0            -  80549.530260   1762852   41933215  ...                      0  \\\n",
       "1            -      0.000000         0          0  ...                      0   \n",
       "2            -      0.000000         0          0  ...                      0   \n",
       "3            -      0.000000         0          0  ...                      0   \n",
       "4          dns      0.000549         0        298  ...                      0   \n",
       "...        ...           ...       ...        ...  ...                    ...   \n",
       "339016       -      0.021031       383          0  ...                      0   \n",
       "339017       -      0.021857       226          0  ...                      0   \n",
       "339018       -      0.018836       383          0  ...                      0   \n",
       "339019       -      0.018866       383          0  ...                      0   \n",
       "339020       -      0.034534       383          0  ...                      0   \n",
       "\n",
       "        http_status_code  http_user_agent  http_orig_mime_types   \n",
       "0                      0                -                     -  \\\n",
       "1                      0                -                     -   \n",
       "2                      0                -                     -   \n",
       "3                      0                -                     -   \n",
       "4                      0                -                     -   \n",
       "...                  ...              ...                   ...   \n",
       "339016                 0                -                     -   \n",
       "339017                 0                -                     -   \n",
       "339018                 0                -                     -   \n",
       "339019                 0                -                     -   \n",
       "339020                 0                -                     -   \n",
       "\n",
       "        http_resp_mime_types        weird_name weird_addl  weird_notice   \n",
       "0                          -  bad_TCP_checksum          -             F  \\\n",
       "1                          -                 -          -             -   \n",
       "2                          -  bad_TCP_checksum          -             F   \n",
       "3                          -                 -          -             -   \n",
       "4                          -  bad_UDP_checksum          -             F   \n",
       "...                      ...               ...        ...           ...   \n",
       "339016                     -                 -          -             -   \n",
       "339017                     -                 -          -             -   \n",
       "339018                     -                 -          -             -   \n",
       "339019                     -                 -          -             -   \n",
       "339020                     -                 -          -             -   \n",
       "\n",
       "        label    type  \n",
       "0           0  normal  \n",
       "1           0  normal  \n",
       "2           0  normal  \n",
       "3           0  normal  \n",
       "4           0  normal  \n",
       "...       ...     ...  \n",
       "339016      0  normal  \n",
       "339017      0  normal  \n",
       "339018      0  normal  \n",
       "339019      0  normal  \n",
       "339020      0  normal  \n",
       "\n",
       "[9339021 rows x 46 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 112. GiB for an array with shape (12821, 9339021) and data type bool",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m df[categorical_cols] \u001b[38;5;241m=\u001b[39m df[categorical_cols]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mfillna(x\u001b[38;5;241m.\u001b[39mmode()[\u001b[38;5;241m0\u001b[39m]))\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Encode the categorical variables (excluding 'type')\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_dummies\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcategorical_cols\u001b[49m\u001b[43m)\u001b[49m   \u001b[38;5;66;03m# FIXME: MemoryError: Unable to allocate 112. GiB for an array with shape (12821, 9339021) and data type bool\u001b[39;00m\n\u001b[0;32m     21\u001b[0m                                                     \u001b[38;5;66;03m# Perhaps this error is due to the size of the dataset?\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Now, 'type' is not altered and is ready to be used as the target variable for model training.\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Proceed with scaling the numeric features\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\reshape\\encoding.py:203\u001b[0m, in \u001b[0;36mget_dummies\u001b[1;34m(data, prefix, prefix_sep, dummy_na, columns, sparse, drop_first, dtype)\u001b[0m\n\u001b[0;32m    199\u001b[0m     with_dummies \u001b[38;5;241m=\u001b[39m [data\u001b[38;5;241m.\u001b[39mselect_dtypes(exclude\u001b[38;5;241m=\u001b[39mdtypes_to_encode)]\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col, pre, sep \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(data_to_encode\u001b[38;5;241m.\u001b[39mitems(), prefix, prefix_sep):\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;66;03m# col is (column_name, column), use just column data here\u001b[39;00m\n\u001b[1;32m--> 203\u001b[0m     dummy \u001b[38;5;241m=\u001b[39m \u001b[43m_get_dummies_1d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    205\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprefix_sep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    207\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdummy_na\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdummy_na\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    208\u001b[0m \u001b[43m        \u001b[49m\u001b[43msparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    209\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdrop_first\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_first\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    210\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    211\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    212\u001b[0m     with_dummies\u001b[38;5;241m.\u001b[39mappend(dummy)\n\u001b[0;32m    213\u001b[0m result \u001b[38;5;241m=\u001b[39m concat(with_dummies, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\reshape\\encoding.py:324\u001b[0m, in \u001b[0;36m_get_dummies_1d\u001b[1;34m(data, prefix, prefix_sep, dummy_na, sparse, drop_first, dtype)\u001b[0m\n\u001b[0;32m    322\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    323\u001b[0m     eye_dtype \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mbool_\n\u001b[1;32m--> 324\u001b[0m dummy_mat \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meye\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumber_of_cols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meye_dtype\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m    326\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dummy_na:\n\u001b[0;32m    327\u001b[0m     \u001b[38;5;66;03m# reset NaN GH4446\u001b[39;00m\n\u001b[0;32m    328\u001b[0m     dummy_mat[codes \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 112. GiB for an array with shape (12821, 9339021) and data type bool"
     ]
    }
   ],
   "source": [
    "# Define features to drop, including IP addresses, ports, and other specified features\n",
    "features_to_drop = ['src_ip', 'dst_ip', 'src_port', 'service','dst_port', 'ssl_version', 'ssl_cipher', 'ssl_subject', \n",
    "                    'ssl_issuer','dns_query','dns_qclass','dns_qtype','dns_rcode','http_request_body_len','http_version', \n",
    "                    'http_trans_depth','http_method','http_uri','http_response_body_len','http_status_code','http_user_agent',\n",
    "                    'http_orig_mime_types','http_resp_mime_types','weird_name','weird_addl','weird_notice', 'ts']\n",
    "df = df.drop(columns=features_to_drop)\n",
    "\n",
    "# Exclude 'type' from the list of categorical columns for encoding\n",
    "categorical_cols = df.select_dtypes(include=['object', 'bool']).columns.tolist()\n",
    "categorical_cols.remove('type')  # Exclude 'type' column\n",
    "\n",
    "# Fill missing numeric values with the median\n",
    "numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "df[numeric_cols] = df[numeric_cols].apply(lambda x: x.fillna(x.median()))\n",
    "\n",
    "# Fill missing categorical values with the mode (excluding 'type')\n",
    "df[categorical_cols] = df[categorical_cols].apply(lambda x: x.fillna(x.mode()[0]))\n",
    "\n",
    "# Encode the categorical variables (excluding 'type')\n",
    "df = pd.get_dummies(df, columns=categorical_cols)   # FIXME: MemoryError: Unable to allocate 112. GiB for an array with shape (12821, 9339021) and data type bool\n",
    "                                                    # Perhaps this error is due to the size of the dataset?\n",
    "\n",
    "# Now, 'type' is not altered and is ready to be used as the target variable for model training.\n",
    "\n",
    "# Proceed with scaling the numeric features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df[numeric_cols] = scaler.fit_transform(df[numeric_cols])\n",
    "\n",
    "# Your dataset is now ready for training and testing the model.\n",
    "\n",
    "# After preprocessing your training data\n",
    "trained_columns = df.columns.tolist()\n",
    "trained_columns = list(dict.fromkeys(trained_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_df(df, trained_columns):\n",
    "    # Define features to drop, including IP addresses, ports, and other specified features\n",
    "    features_to_drop = ['src_ip', 'dst_ip', 'src_port', 'service','dst_port', 'ssl_version', 'ssl_cipher', 'ssl_subject', 'ssl_issuer','dns_query','dns_qclass','dns_qtype','dns_rcode','http_request_body_len','http_version', 'http_trans_depth','http_method','http_uri','http_response_body_len','http_status_code','http_user_agent','http_orig_mime_types','http_resp_mime_types','weird_name','weird_addl','weird_notice']\n",
    "    df = df.drop(columns=features_to_drop)\n",
    "\n",
    "    # Exclude 'type' from the list of categorical columns for encoding\n",
    "    categorical_cols = df.select_dtypes(include=['object', 'bool']).columns.tolist()\n",
    "    categorical_cols.remove('type')  # Exclude 'type' column\n",
    "\n",
    "    # Fill missing numeric values with the median\n",
    "    numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "    df[numeric_cols] = df[numeric_cols].apply(lambda x: x.fillna(x.median()))\n",
    "\n",
    "    # Fill missing categorical values with the mode (excluding 'type')\n",
    "    df[categorical_cols] = df[categorical_cols].apply(lambda x: x.fillna(x.mode()[0]))\n",
    "\n",
    "    # Encode the categorical variables (excluding 'type')\n",
    "    df = pd.get_dummies(df, columns=categorical_cols)\n",
    "    df = df.reindex(columns=trained_columns, fill_value=0)\n",
    "\n",
    "\n",
    "    # Now, 'type' is not altered and is ready to be used as the target variable for model training.\n",
    "\n",
    "    # Proceed with scaling the numeric features\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    df[numeric_cols] = scaler.fit_transform(df[numeric_cols])\n",
    "\n",
    "    # Your dataset is now ready for training and testing the model.\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separate the features (X) from the target variable (y)\n",
    "X = df.drop('type', axis=1)  # Features\n",
    "y = df['type']  # Target variable\n",
    "\n",
    "# Split the dataset into training (80%) and testing (20%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Check the size of the splits\n",
    "print(f\"Training set size: {X_train.shape[0]} rows\")\n",
    "print(f\"Testing set size: {X_test.shape[0]} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Initialize the Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42, criterion='entropy')\n",
    "\n",
    "# Train the model on the training set\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Display a message to confirm training completion\n",
    "print(\"Decision Tree model training completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Predict the labels for the test set\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "# Calculate and print the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy of the Decision Tree model on the test set: {accuracy:.2f}\")\n",
    "\n",
    "# Generate a classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plot_tree(dt_classifier, filled=True, feature_names=X.columns, class_names=y.unique())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the model on new data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following datasets can be found on processed network dataset located in the TON_IoT link in [this UNSW webpage](https://research.unsw.edu.au/projects/unsw-nb15-dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Network_dataset_14 contains instances of normal traffic and ddos attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdata = pd.read_csv('Network_dataset_14.csv')\n",
    "\n",
    "newdata2 = newdata.drop('ts', axis=1)\n",
    "\n",
    "new_data_preprocessed = preprocess_df(newdata2, trained_columns)\n",
    "\n",
    "X_new_data = new_data_preprocessed.drop('type', axis=1)\n",
    "y_new = new_data_preprocessed['type']\n",
    "\n",
    "y_new_data = dt_classifier.predict(X_new_data)\n",
    "\n",
    "new_accuracy = accuracy_score(y_new, y_new_data)\n",
    "\n",
    "print(f\"Accuracy of the Decision Tree model on the test set: {new_accuracy:.2f}\")\n",
    "\n",
    "# Generate a classification report\n",
    "new_report = classification_report(y_new, y_new_data)\n",
    "print(\"Classification Report:\\n\", new_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Network_dataset_23 contains instances of normal traffic and backdoor attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdata = pd.read_csv('Network_dataset_23.csv')\n",
    "\n",
    "newdata2 = newdata.drop('ts', axis=1)\n",
    "\n",
    "new_data_preprocessed = preprocess_df(newdata2, trained_columns)\n",
    "\n",
    "X_new_data = new_data_preprocessed.drop('type', axis=1)\n",
    "y_new = new_data_preprocessed['type']\n",
    "\n",
    "y_new_data = dt_classifier.predict(X_new_data)\n",
    "\n",
    "new_accuracy = accuracy_score(y_new, y_new_data)\n",
    "\n",
    "print(f\"Accuracy of the Decision Tree model on the test set: {new_accuracy:.2f}\")\n",
    "\n",
    "# Generate a classification report\n",
    "new_report = classification_report(y_new, y_new_data)\n",
    "print(\"Classification Report:\\n\", new_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
